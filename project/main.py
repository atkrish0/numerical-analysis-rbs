# -*- coding: utf-8 -*-
"""MAIN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mGrxMYBmIU7puMHn4mqvKCFMmJo2-v1X

# Housekeeping (Importing libraries, loading datasets)
"""

from utility import random_number_generator as rng
from utility import variance_reduction as vr

import pandas as pd
import numpy as np
from datetime import datetime
import time

import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import plotly.graph_objects as go
import seaborn as sns

from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from scipy.stats import qmc
from scipy.stats import norm

# secured overnight financing rate, sourced from the st. louis fred
sofr = pd.read_csv('data/FRED_SOFR.csv', parse_dates=['DATE'], index_col='DATE')

# Load Market Yield on U.S. Treasury Securities at X-Year Constant Maturity, Quoted on an Investment Basis
dgs1 = pd.read_csv('data/DGS1.csv', parse_dates=['DATE'], index_col='DATE')
dgs2 = pd.read_csv('data/DGS2.csv', parse_dates=['DATE'], index_col='DATE')
dgs5 = pd.read_csv('data/DGS5.csv', parse_dates=['DATE'], index_col='DATE')
dgs10 = pd.read_csv('data/DGS10.csv', parse_dates=['DATE'], index_col='DATE')
dgs30 = pd.read_csv('data/DGS30.csv', parse_dates=['DATE'], index_col='DATE')

# combine them all
yc = pd.concat([dgs1.rename(columns={'DGS1': '1Y'}),
                              dgs2.rename(columns={'DGS2': '2Y'}),
                              dgs5.rename(columns={'DGS5': '5Y'}),
                              dgs10.rename(columns={'DGS10': '10Y'}),
                              dgs30.rename(columns={'DGS30': '30Y'})], axis=1)

"""# I. Exploratory Data Analysis"""

# check formissing values and prepare for imputation
print("\nMissing values in SOFR Data:", sofr.isna().sum())
print("Missing values in Yield Curve Data:", yc.isna().sum())

print("\nSOFR Summary Statistics:")
print(sofr.describe())

print("\nYield Curve Summary Statistics:")
print(yc.describe())

# Ensure SOFR data is numeric and drop any non-numeric rows (if any)
sofr['SOFR'] = pd.to_numeric(sofr['SOFR'], errors='coerce')
sofr = sofr.dropna()  # Drop rows where SOFR might be NaN after conversion

# Plot SOFR over time
plt.figure(figsize=(10, 5))
plt.plot(sofr.index, sofr['SOFR'], label='SOFR', color='blue')
plt.title("SOFR Over Time")
plt.xlabel("Date")
plt.ylabel("SOFR Rate (%)")
plt.legend()
plt.show()

# Ensure all yield curve columns are numeric and handle any non-numeric values
for col in yc.columns:
    yc[col] = pd.to_numeric(yc[col], errors='coerce')

yc = yc.interpolate(method='time').dropna()  # Interpolate missing values based on time index

plt.figure(figsize=(12, 8))
for col in yc.columns:
    plt.plot(yc.index, yc[col], label=col)

plt.title("Yield Curve Over Time for Different Maturities")
plt.xlabel("Date")
plt.ylabel("Yield (%)")
plt.legend(loc='upper left')
plt.show()

sofr['SOFR'] = pd.to_numeric(sofr['SOFR'], errors='coerce')
sofr = sofr.dropna()

sofr['SOFR_MA'] = sofr['SOFR'].rolling(window=30).mean()

plt.figure(figsize=(12, 6))
plt.plot(sofr.index, sofr['SOFR'], label='SOFR', color='dodgerblue')
plt.plot(sofr.index, sofr['SOFR_MA'], label='30-Day Moving Average', color='orange', linestyle='--')
annot_date = datetime(2020, 3, 16)
plt.annotate('COVID-19 Shock',
             xy=(annot_date, sofr.loc[annot_date, 'SOFR']),
             xytext=(datetime(2020, 6, 1), 2.0),
             arrowprops=dict(facecolor='red', arrowstyle='->'), color='red')

plt.title("SOFR Over Time with 30-Day Moving Average", fontsize=14, fontweight='bold')
plt.xlabel("Date", fontsize=12)
plt.ylabel("SOFR Rate (%)", fontsize=12)
plt.legend()
plt.grid(True, linestyle='--', alpha=0.7)

plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
plt.gca().xaxis.set_major_locator(mdates.YearLocator())
plt.gcf().autofmt_xdate()

plt.show()

recession_periods = [
    ('1969-12-01', '1970-11-01'),
    ('1973-11-01', '1975-03-01'),
    ('1980-01-01', '1980-07-01'),
    ('1981-07-01', '1982-11-01'),
    ('1990-07-01', '1991-03-01'),
    ('2001-03-01', '2001-11-01'),
    ('2007-12-01', '2009-06-01'),
    ('2020-02-01', '2020-05-01')
]

start_date = '1975-01-01'
filtered_yc = yc[yc.index >= start_date]
filtered_yc['10Y-2Y Spread'] = filtered_yc['10Y'] - filtered_yc['2Y']
filtered_yc['5Y-1Y Spread'] = filtered_yc['5Y'] - filtered_yc['1Y']
filtered_yc['30Y-10Y Spread'] = filtered_yc['30Y'] - filtered_yc['10Y']
filtered_yc['10Y-1Y Spread'] = filtered_yc['10Y'] - filtered_yc['1Y']

plt.figure(figsize=(14, 8))
plt.plot(filtered_yc.index, filtered_yc['10Y-2Y Spread'], color='purple', label='10Y-2Y Spread')
plt.plot(filtered_yc.index, filtered_yc['5Y-1Y Spread'], color='teal', label='5Y-1Y Spread')
plt.plot(filtered_yc.index, filtered_yc['30Y-10Y Spread'], color='blue', label='30Y-10Y Spread')
plt.plot(filtered_yc.index, filtered_yc['10Y-1Y Spread'], color='orange', label='10Y-1Y Spread')

plt.axhline(0, color='red', linestyle='--', label='Zero Line', linewidth=1)

for start, end in recession_periods:
    if start >= start_date:
        plt.axvspan(start, end, color='gray', alpha=0.3)

plt.title("Yield Spreads Over Time with Recession Periods", fontsize=16, fontweight='bold')
plt.xlabel("Date", fontsize=12)
plt.ylabel("Yield Spread (%)", fontsize=12)
plt.grid(axis='y', linestyle='--', alpha=0.5)
plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=3, fontsize=10, frameon=False)
plt.xticks(fontsize=10)
plt.yticks(fontsize=10)
plt.tight_layout()
plt.show()

"""are all these spreads required to be plotted? whats the significance?

# II: Construction of Forward Rate Curves
"""

def calculate_forward_rate(yield_curve, t1, t2):
    # Spot rates for maturities t1 and t2
    r_t1 = yield_curve[f"{t1}Y"]
    r_t2 = yield_curve[f"{t2}Y"]

    forward_rate = ((1 + r_t2 / 100) ** t2 / (1 + r_t1 / 100) ** t1) ** (1 / (t2 - t1)) - 1
    return forward_rate * 100

forward_curve = pd.DataFrame(index=yc.index)
forward_curve['1Y-2Y'] = calculate_forward_rate(yc, 1, 2)
forward_curve['2Y-5Y'] = calculate_forward_rate(yc, 2, 5)
forward_curve['5Y-10Y'] = calculate_forward_rate(yc, 5, 10)
forward_curve['10Y-30Y'] = calculate_forward_rate(yc, 10, 30)

print("Forward Rate Curve:")
print(forward_curve.head())

plt.figure(figsize=(12, 8))
for column in forward_curve.columns:
    plt.plot(forward_curve.index, forward_curve[column], label=f"Forward Rate {column}")

plt.title("Forward Rate Curve Over Time")
plt.xlabel("Date")
plt.ylabel("Forward Rate (%)")
plt.legend()
plt.grid(True, linestyle='--', alpha=0.7)
plt.show()

"""# III. Analysis of Yield Curve Movements using PCA"""

yield_data = yc[['1Y', '2Y', '5Y', '10Y', '30Y']]

scaler = StandardScaler()
yield_data_std = scaler.fit_transform(yield_data)

pca = PCA(n_components=5)
pca.fit(yield_data_std)
yield_pca = pca.transform(yield_data_std)
explained_variance = pca.explained_variance_ratio_

plt.figure(figsize=(10, 6))
plt.bar(range(1, len(explained_variance) + 1), explained_variance * 100, color='dodgerblue')
plt.title("Variance Explained by Each Principal Component")
plt.xlabel("Principal Component")
plt.ylabel("Variance Explained (%)")
plt.show()

"""As expected, we see that most of the variance has been captured by the first PC. With the rest being captured by 2 and 3."""

# Convert the PCA components to a DataFrame for further analysis
pca_df = pd.DataFrame(yield_pca, index=yield_data.index, columns=[f'PC{i+1}' for i in range(yield_pca.shape[1])])

plt.figure(figsize=(12, 8))
plt.plot(pca_df.index, pca_df['PC1'], label='PC1 (Level)', color='purple')
plt.plot(pca_df.index, pca_df['PC2'], label='PC2 (Slope)', color='teal')
plt.plot(pca_df.index, pca_df['PC3'], label='PC3 (Curvature)', color='orange')
plt.title("First Three Principal Components Over Time")
plt.xlabel("Date")
plt.ylabel("Principal Component Value")
plt.legend()
plt.grid(True, linestyle='--', alpha=0.5)
plt.show()

"""The principal components are used to calibrate the volatility structure of the HJM model. This ensures that the stochastic simulation of forward rates reflects historical yield curve dynamics. Each PC is associated with a factor in the HJM model, which influences how forward rates evolve over time.

# IV: Stochastic Modeling with the HJM Framework
"""

# parameters for the simulation
# n_steps = 100
# n_simulations = 10
# dt = 1/252
# volatility = 0.01

"""## i. Incorporating PCA factors for Volatility Calcualtions"""

# eigenvectors: factor loadings
# eigenvalues: explained variance

def calculate_volatility(t, T_index, eigenvectors, eigenvalues, n_factors=3):
    volatility = 0
    for i in range(min(n_factors, len(eigenvalues))):
        volatility += eigenvectors[i, T_index] * np.sqrt(eigenvalues[i])
    return volatility

"""## iii. Monte Carlo Simulation"""

n_steps = 100
n_simulations = 10
dt = 1 / 252

print("Select a random number generation method:")
print("1: Standard Normal (numpy.random.normal)")
print("2: Uniform Distribution (numpy.random.uniform)")
print("3: Sobol Sequence (scipy.stats.qmc.Sobol)")
print("4: Halton Sequence (scipy.stats.qmc.Halton)")

user_choice = int(input("Enter your choice (1/2/3/4/5): "))
rng_methods = {1: "normal", 2: "uniform", 3: "sobol", 4: "halton"}
rng_method = rng_methods.get(user_choice, "normal")

print("Columns in yc:", yc.columns)
available_maturities = ['1Y', '2Y', '5Y', '10Y', '30Y']

initial_forward_rates = yc[available_maturities].iloc[-1].values
n_maturities = len(initial_forward_rates)

simulated_forward_rates = np.zeros((n_steps, n_maturities, n_simulations))
simulated_forward_rates[0, :, :] = initial_forward_rates[:, np.newaxis]

#dW = np.random.normal(0, np.sqrt(dt), (n_maturities, n_simulations))
# Generate random numbers
# print(f"Using RNG Method: {rng_method}")

# # Check the shape and values of generated random numbers
# print(f"Shape of generated dW: {dW.shape}")
# print(f"Sample values from dW: {dW[:5]}")
#dW = np.random.normal(0, np.sqrt(dt), (n_maturities, n_simulations))

for i in range(1, n_steps):

    # dW = rng.generate_random_numbers(rng_method, (n_maturities, n_simulations), seed=42)
    # dW *= np.sqrt(dt)

    dW_direct = np.random.normal(0, np.sqrt(dt), (n_maturities, n_simulations))
    dW_rn = rng.generate_random_numbers("normal", (n_maturities, n_simulations), seed=42, dt=dt)

    for j in range(n_maturities):
        volatility = calculate_volatility(i * dt, j, pca.components_, pca.explained_variance_)
        drift = 0
        diffusion = volatility * dW[j, :]
        simulated_forward_rates[i, j, :] = simulated_forward_rates[i-1, j, :] * np.exp(drift * dt + diffusion)

dates = pd.date_range(start=yc.index[-1], periods=n_steps, freq='D')
simulated_paths = {f'Maturity {m}Y': pd.DataFrame(simulated_forward_rates[:, j, :], index=dates) for j, m in enumerate([1, 2, 5, 10, 30])}

plt.figure(figsize=(14, 8))
for maturity, paths in simulated_paths.items():
    plt.plot(paths.index, paths.mean(axis=1), label=f"Average {maturity} Path")
    for path in paths.columns:
        plt.plot(paths.index, paths[path], color='lightgray', alpha=0.3)

plt.title("Simulated Forward Rate Paths (HJM Model with PCA-Based Volatility)")
plt.xlabel("Date")
plt.ylabel("Forward Rate (%)")
plt.legend()
plt.grid(True, linestyle='--', alpha=0.7)
plt.show()

dW_direct = np.random.normal(0, np.sqrt(dt), (n_maturities, n_simulations))
dW_rn = rng.generate_random_numbers("normal", (n_maturities, n_simulations), seed=42, dt=dt)

print("Direct RNG: Mean =", dW_direct.mean(), "Std Dev =", dW_direct.std())
print("RNG Module: Mean =", dW_rn.mean(), "Std Dev =", dW_rn.std())

"""^ Some issue with the apths generated, recheck. normal is fine as it is. but pakage format give weird plots

# Computational Time Comparison

# ...

# ...

# ...

# V. Pricing IR Derivatives
"""

cap_rate = 0.03
floor_rate = 0.02
discount_rate = 0.01
maturities = np.array([1, 2, 5, 10, 30])

# parameters (as used inHJM model)
n_steps = 100
n_simulations = 10
dt = 1 / 252

cap_payoffs = np.zeros((n_steps, n_simulations))
floor_payoffs = np.zeros((n_steps, n_simulations))

for i in range(1, n_steps):
    for j in range(n_simulations):
        for k, T in enumerate(maturities[:-1]):
            fwd_rate = simulated_forward_rates[i, k, j]

            caplet_payoff = max(fwd_rate - cap_rate, 0)
            cap_payoffs[i, j] += caplet_payoff

            floorlet_payoff = max(floor_rate - fwd_rate, 0)
            floor_payoffs[i, j] += floorlet_payoff

average_cap_payoffs = np.mean(cap_payoffs, axis=1)
average_floor_payoffs = np.mean(floor_payoffs, axis=1)

cap_price = np.sum(average_cap_payoffs * np.exp(-discount_rate * np.arange(1, n_steps+1) * dt))
floor_price = np.sum(average_floor_payoffs * np.exp(-discount_rate * np.arange(1, n_steps+1) * dt))

print(f"Cap Price: {cap_price:.4f}")
print(f"Floor Price: {floor_price:.4f}")

from utility.variance_reduction import price_with_variance_reduction

print("Select a variance reduction method:")
print("1: Standard Monte Carlo")
print("2: Antithetic Variates")
print("3: Control Variates")

user_choice = int(input("Enter your choice (1/2/3): "))
vr_methods = {1: "standard", 2: "antithetic", 3: "control"}
vr_method = vr_methods.get(user_choice, "standard")

cap_rate = 0.03
floor_rate = 0.02
discount_rate = 0.01
dt = 1 / 252  # Time step
discount_factors = np.exp(-discount_rate * np.arange(1, n_steps+1) * dt)

# control placeholder
analytical_price = 0.05
initial_forward_rates = yc[available_maturities].iloc[-1].values  # last row of spot rates
dt = 1 / 252
volatility = 0.01
n_steps = 100
n_simulations = 10

cap_price, cap_std_dev = price_with_variance_reduction(
    vr_method,
    simulated_forward_rates,
    cap_rate,
    discount_factors,
    analytical_price if vr_method == "control" else None,
    initial_forward_rates=initial_forward_rates,
    dt=dt,
    volatility=volatility,
    n_steps=n_steps,
    n_simulations=n_simulations
)

floor_price, floor_std_dev = price_with_variance_reduction(
    vr_method,
    simulated_forward_rates,
    floor_rate,
    discount_factors,
    analytical_price if vr_method == "control" else None,
    initial_forward_rates=initial_forward_rates,
    dt=dt,
    volatility=volatility,
    n_steps=n_steps,
    n_simulations=n_simulations
)

print(f"Variance Reduction Method: {vr_method.capitalize()}")
print(f"Cap Price: {cap_price:.4f}, Standard Deviation: {cap_std_dev:.4f}")
print(f"Floor Price: {floor_price:.4f}, Standard Deviation: {floor_std_dev:.4f}")

